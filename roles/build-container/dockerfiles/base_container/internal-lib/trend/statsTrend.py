'''
Created on May 2015
Update on May 2017

Use this code to caclulate trend on one metric using prophet
At its core, the module gives an additive regression model
with four main components:

    A piecewise linear or logistic growth curve trend. Prophet
     automatically detects changes in trends by selecting changepoints
     from the data.
    A yearly seasonal component modeled using Fourier series.
    A weekly seasonal component using dummy variables.
    A user-provided list of important holidays.

For each timestamp, you get the predicted value yhat
in the rightmost column  of the dataframe returned by
prediction and all the components making up the prediction.
In addition, yhat_lower and yhat_upper show the exact range 
of the uncertainty interval.

Note : install prophet as 
$ conda install pystan
# pip install fbprophet
(be careful install as a user the pystan and as root the fbpropet...)

@author: capgemini.cloudinfrastructurefrance.ac4dc
@copyright: capgemini 2015,2016,2017
'''

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import fbprophet as fb
import os
# import the configuration for this module
from config.TRD_LSTMnn import lstmnnsettings
import ano.api.peakDetection as pk


#===============================================================================
# removePeaksFromDf
#    @args:
#            df : a timeseries (timestamp,value) indexed on timestamp
#            dfPeaks : a timeseries (timestamp, value) of anomalies indexed
#                      on timestamp
#    @return:
#            df : a timeseries (timestamp,value) where peaks are replaced by
#                 value NaN (not a number)
# This function removes all anomalies from a series, the dfPeaks is only a
# copy of timestamp,value where is row is suspected to be a peak...This avoid
# miscalculations by prophet.
#===============================================================================
def removePeaksFromDf(df,dfPeaks):
    # it seems that due to a bug we cannot express this update
    # in one line form 
    # for each peak datetime found
    for y in dfPeaks.index :
        # for each normal datetime series found
        for x in df.index:
            # if date found in peak is equal to the date found in series
            # then update the value with NaN to avoid the algorithm integrates
            # the peak.
            if (x==y):
                # find the row
                row= df.index.get_loc(y)
                # update row,col
                df.iloc[row, 0] = np.nan
                break            
    return df
    
#===============================================================================
# NormalizeDataFrame
#    @args :
#        df : a timeseries as (timeStamp,value) where the timestamp is
#             the datetime index !
#        metricName : the name of the field where value resides 
#        dfpeaks : a timeseries of peaks to remove as (timeStamp,value)
#                  could be a None value if no peaks to process
#    @return:
#        pdf : a normalized dataframe to be used by Prophet
# Prophet needs to have a series with two fields (ds,value) where value
# is normalized and value is not an outlier from the original series (df). 
#===============================================================================
def NormalizeDataFrame (metricName,df,dfPeaks=None):
    # get config
    debug = lstmnnsettings['stats_trend']['debug'] 
    removePeaks=True
    if dfPeaks is None:
        removePeaks=False
    if removePeaks==True:
        # call removePeaksFromDf
        pDf = removePeaksFromDf(df,dfPeaks)
    else:
        pDf = df 
    # now adapt column names as prophet need a dataframe with two
    # fields ds and y, where ds is the datetime field but not indexed !
    pDf.index.name='ds'
    df.rename(columns={metricName:'y'},inplace=True)
    ' remove index ds and transform it as a column'
    df.reset_index(inplace=True)
    if debug==True:
        print ("After transfo")
        print pDf.index
        print pDf
    # log-transform y
    #     pDf['y'] = np.log(pDf['y']+1e-06)
    return pDf

#===============================================================================
# unnormalizeForecast
#    @args :
#        resultsDf : a Df generated by forecast
#        freq : the frequency like 'H' (hour) our 'D' (day)
#    @return:
#        resultsDF with values unormalized
# Not used - historically convert the content of all numerical fields if they
# were log normalized.
# Note that if frequency is 'D' there are more fields than 'H'
# Only fields are printed by this function.
#===============================================================================
def unnormalizeForecast(resultsDf,freq):   
    debug = lstmnnsettings['stats_trend']['debug'] 
    # unormalize results (inverse log)
    if freq=='D':
        features=[
            'trend',
            'seasonal_lower',
            'seasonal_upper',
            'trend_lower',
            'trend_upper',
            'yhat_lower',
            'yhat_upper',
            'weekly',
            'weekly_lower',
            'weekly_upper',
            'yearly',
            'yearly_lower',
            'yearly_upper',
            'seasonal',
            'yhat']
    else:
        # if freq = 'H' we do not have weekly and yearly values to convert
        # (always 0.0)
        features =[
            'trend',
            'trend_lower',
            'trend_upper',
            'yhat_lower',
            'yhat_upper',
            'yhat']

#     for field in features:
#         resultsDf[field]=np.exp(resultsDf[field]).round()+1e-06
    if debug==True:
        print features
    return resultsDf
    
       
#===============================================================================
# buildModel
#    @args:
#        pDf : prophet data frame (ds,y)
#        holidaysDf : simple dataframe (with no datetime index) as (ds)
#    @return :
#        a model instantiated with optional holidays
#===============================================================================
def buildModel(pDf,holidaysDf):
    # get configuration
    # increasing changepoint_prior_scale, will increase the forecast uncertainty
    # Uncertainty in the trend use change_prior_scale = 0.5
    # interval.width = 0.95
    # The width of the uncertainty intervals (by default 80%)
    interval_width = lstmnnsettings['stats_trend']['interval_width']
    changepoint_prior_scale = lstmnnsettings['stats_trend']['changepoint_prior_scale']
    # apply model
    if holidaysDf is None:
        dfWithHolidays=None
    else:
        dfWithHolidays = pd.DataFrame({
          'holiday': 'publish',
          'ds': pd.to_datetime(holidaysDf['ds']),
          'lower_window': 0,
          'upper_window': 5,
        })
  
    model = fb.Prophet(changepoint_prior_scale=changepoint_prior_scale,
                       holidays=dfWithHolidays).fit(pDf)
    # if seasonnality use mcmc.samples (which defaults to 0)
    return model

#===============================================================================
# buildTrends
#    @args :
#        model : a prophet model
#        daysPeriods : the number of days applied to the period of data
#                        (if days, put 365 days, if hours and 50 days, put 
#                         50daysx24hours)
#        theFreq : use 'H' for hours or 'D' for days
#    @return :
#        a dataframe series with a lot of fields and that add to the orignal
#        values the daysPeriods value (if you put 4 and the theFreq is 'H' (hour)
#        the system will predict 4 hours more).
#===============================================================================
def buildTrends(model,dayPeriods,theFreq):
    debug = lstmnnsettings['stats_trend']['debug']
    # Python
    future = model.make_future_dataframe(periods=dayPeriods,freq=theFreq)
    if debug==True:
        future.tail()
    forecast = model.predict(future)
    print forecast
    return forecast


#===============================================================================
# buildCoreFilename
# @args :
#            metricName : the name of the metric that would be suffixed to the
#                          the name of file
# returns a string with the path where to put a file as :
#        path/fileNamemetricName (with no extension)
#===============================================================================
def buildCoreFilename(metricName):
    # get config
    fileName = lstmnnsettings['stats_trend']['filename']
    outputPath = lstmnnsettings['common']['output_path']
    outputFile = outputPath + fileName
    outputFile = outputFile + metricName
    return outputFile
#===============================================================================
# save2csv
#    args :
#        forecast : a forecast dataframe 
#        metricName : the name of the metric to save
#    return :
#        always 0
# save a forecast series. Due to a bug we need to create a temporay
# excel file and after that reload it and save it to csv.
# if we have values as 4.61919 e+04 and we save directly with to_csv
# we will found 4.61919 (e+04 is lost...).
#===============================================================================
def save2csv(forecast,metricName):
    # build filenames with path
    xl_filename=buildCoreFilename(metricName)+".xlsx"
    csv_filename=buildCoreFilename(metricName)+".csv"
    # get an excel writer
    writer = pd.ExcelWriter(xl_filename)
    # save forecast 
    forecast.to_excel(writer,'Sheet1')
    writer.save()
    # reload and save to cvs 
    df2 = pd.read_excel(xl_filename) 
    df2.to_csv(csv_filename)
    # remove the excel file
    os.remove(xl_filename)
    return 0
    

#===============================================================================
# loadTest
#     @startOfLabel : name of a counter to find in a test file
#     @return : a df (timestamp, value)
# Load a file formated as (timestamp;Counter;value...) and extract only
# the desired counter
#===============================================================================
def loadTest(counterName):
    # get config
    debug = lstmnnsettings['stats_trend']['debug']
    data_file = "../data/input/LDAP_1.csv"
    df = pd.read_csv(data_file,sep=';',index_col=0,parse_dates=True)
    print df 
    df2 = df[[ 'Counter','Value']]
    df2=df2[[counterName in x for x in df2['Counter']]]
    
    df3=df2[['Value']]
    if debug==True: 
        print df3
    return df3



#===============================================================================
# loadTest2
#    @args:
#        field : a field in a file as (timeStamp, field1, field2,...)
#     @return:
#        df : a dataframe as expected (timesamp,value) that filters the df on the
#              field.
#===============================================================================
def loadMetric(metricFilePath):
    # get config
    debug = lstmnnsettings['stats_trend']['debug']
    data_file = metricFilePath
    df = pd.read_csv(data_file,sep=',',index_col=0,parse_dates=True)
    if debug==True:
        print df
    df2 = df[['Value']]
    if debug==True:
        print df2
    
    return df2



#===============================================================================
# loadTest2
#    @args:
#        field : a field in a file as (timeStamp, field1, field2,...)
#     @return:
#        df : a dataframe as expected (timesamp,value) that filters the df on the
#              field.
#===============================================================================
def loadTest2(Field):
    # get config
    debug = lstmnnsettings['stats_trend']['debug']
    data_file = "/home/sogeti/Bureau/metrics/demo1_router_1_trafficIn.csv"
    df = pd.read_csv(data_file,sep=',',index_col=0,parse_dates=True)
    if debug==True:
        print df
    df2 = df[[Field]]
    if debug==True:
        print df2
    
    return df2
        
# def doTest():  
#     # get config
#     debug = lstmnnsettings['stats_trend']['debug']  
#     # load values as (timeStamp,values)
#     data_file = "../data/input/All-Web-Site-Data-Audience-Overview.xlsx"
#     df = pd.read_excel(data_file)
#     # load peaks as (timestamp,values)
#     # load holidays as (timestamp)
#     holidays_file = "../data/input/holidays2016.csv"
#     holidaysDf=pd.read_csv(holidays_file)
#     if debug==True:
#         print holidaysDf
#     # normalize df  
#     pDf = NormalizeDataFrame(df, dfPeaks=None)
#     # build series with holidays
#     model = buildModel(pDf,holidaysDf)
#     # fit model with period of prediction of 365 days ...
#     forecast=buildTrends(model,365,'D')
#     # not used only for API
#     forecast=unnormalizeForecast(forecast,'D')
#     if debug==True:
#         print "*********** final*************"
#         print forecast
#     forecast.to_csv("../data/output_pred/trends.csv") 
 
def doTest2_ConstantValuePredict():
    # get config
    debug = lstmnnsettings['stats_trend']['debug']  
    # do a test in hours this time...
    # load values as (timeStamp,values)
    df2=loadTest("MemoryUsedPercent")
    #print df.head()
    # load peaks as (timestamp,values)
    # load holidays as (timestamp)
    holidays_file = "../data/input/holidays2016.csv"
    holidaysDf=pd.read_csv(holidays_file)
    if debug==True:
        print holidaysDf
    # normalize df  
    pDf = NormalizeDataFrame('Value',df2, dfPeaks=None)
    
    # build series with holidays
    model = buildModel(pDf,holidaysDf)
    # fit model with period of prediction of 4 hours ...
    forecast=buildTrends(model,4,'H')
    forecast=unnormalizeForecast(forecast,'H')
    if debug==True:
        print "*********** final*************"
        print forecast
    #forecast.to_csv("../data/output_pred/trends2.csv")   
    save2csv(forecast,"MemoryUsedPercent") 
    
def doTest3_NonConstantValuePredict():
    # get config
    debug = lstmnnsettings['stats_trend']['debug'] 
    # do a test in hours this time...
    # load values as (timeStamp,values)
    df3=loadTest("CPULoadPercent")
    if debug==True:
        print df3
    
    # load peaks as (timestamp,values)
    # load holidays as (timestamp)
 
    holidays_file = "../data/input/holidays2016.csv"
    holidaysDf=pd.read_csv(holidays_file)
    if debug==True:
        print holidaysDf
    # normalize df  
    pDf = NormalizeDataFrame("Value",df3, dfPeaks=None)
    if debug==True:
        print pDf
    # build series with holidays
    model = buildModel(pDf,holidaysDf)
    # fit model with period of prediction of 4 hours ...
    forecast=buildTrends(model,4*24*31*365,'D')
    forecast=unnormalizeForecast(forecast,'D')
    if debug==True:
        print "*********** final*************"
        print forecast
    #forecast.to_csv("../data/output_pred/trends3.csv")   
    save2csv(forecast,"CPULoadPercent") 
 
def doTest4_2hours():   
    # get config
    debug = lstmnnsettings['stats_trend']['debug'] 
    # do a test in hours this time...
    # load values as (timeStamp,values)
     
    df4=loadTest2("Traffic_in")
     
    # load peaks as (timestamp,values)
    # load holidays as (timestamp)
 
    holidays_file = "../data/input/holidays2016.csv"
    holidaysDf=pd.read_csv(holidays_file)
    if debug==True:
        print holidaysDf
    # normalize df  
    pDf = NormalizeDataFrame("Traffic_in",df4, dfPeaks=None)
    if debug==True:
        print pDf
    # build series with holidays
    
    model = buildModel(pDf,holidaysDf)
    # fit model with period of prediction of 4 hours ...
    forecast=buildTrends(model,4,'H')
    forecast=unnormalizeForecast(forecast,'H')
    if debug==True:
        print "*********** final*************"
        print forecast
    save2csv(forecast,"Traffic_in")
    
def doTest5_ValuesWithPeakDetect():
    # get config
    debug = lstmnnsettings['stats_trend']['debug'] 
    # do a test in hours this time...
    # load values as (timeStamp,values)
     
    df5=loadTest2("Value")
     
    # load peaks as (timestamp,values)
    # calculate peaks - this is not done in a standard function
    # we simulate here a job that has been scheduled
    #df5['timeStamp'] = pd.to_datetime(df5['timeStamp']) 
    #ts = df5.set_index('timeStamp')
    ts=df5['Traffic_in']
    if debug==True:
        print ts
    peaksDetected=pk.peakDetection(ts,"Value")
    if  peaksDetected==False:
        peaksLoaded=None
        print("No Peak")
    else:
        peaksLoaded=pd.read_csv("../data/output_res/peak_detection_demo1_router_2_traffic_in.csv",
                                sep=',',header=None,index_col=0,parse_dates=True)
        
        peaksLoaded.columns = [ "y"]
        print("Peak Loaded")
    if debug==True:
        print peaksLoaded
    # load holidays as (timestamp)
    holidays_file = "../data/input/holidays2016.csv"
    holidaysDf=pd.read_csv(holidays_file)
    if debug==True:
        print holidaysDf
    # normalize df to be prophet compatible
    pDf = NormalizeDataFrame("Value",df5, dfPeaks=peaksLoaded)
    if debug==True:
        print pDf
    # build series with holidays
    model = buildModel(pDf,holidaysDf)
    # fit model with period of prediction of 4 hours ...
    forecast=buildTrends(model,4,'M')
    forecast=unnormalizeForecast(forecast,'M')
    if debug==True:
        print "*********** final*************"
        print forecast
    save2csv(forecast,"Traffic_in")
    
def doTest6_ValuesWithPeakDetect():
    # get config
    debug = lstmnnsettings['stats_trend']['debug'] 
    # do a test in hours this time...
    # load values as (timeStamp,values)
     
    df5=loadTest2("Value")
     
    # load peaks as (timestamp,values)
    # calculate peaks - this is not done in a standard function
    # we simulate here a job that has been scheduled
    #df5['timeStamp'] = pd.to_datetime(df5['timeStamp']) 
    #ts = df5.set_index('timeStamp')
    ts=df5['Value']
#     ts=df5
    if debug==True:
        print ts
    peaksDetected=pk.peakDetection(ts,"Value")
    if  peaksDetected==False:
        peaksLoaded=None
        print("No Peak")
    else:
        peaksLoaded=pd.read_csv("/home/sogeti/Bureau/PREDITC_MAJ/PREDICT/src/data/output_res2/peak_detection_demo1_router_1_trafficIn.csv",
                                sep=',',header=None,index_col=0,parse_dates=True)
        
#         peaksLoaded.columns = [ "y"]
        print("Peak Loaded")
    if debug==True:
        print peaksLoaded
    # load holidays as (timestamp)
    holidays_file = "../data/input/holidays2016.csv"
    holidaysDf=pd.read_csv(holidays_file)
    if debug==True:
        print("VACANCES")
        print holidaysDf
    # normalize df to be prophet compatible
    pDf = NormalizeDataFrame("Value",df5, dfPeaks=peaksLoaded)
    if debug==True:
        print pDf
    # build series with holidays
    model = buildModel(pDf,holidaysDf)
    # fit model with period of prediction of 4 hours ...
    forecast=buildTrends(model,4*24,'H')
    forecast=unnormalizeForecast(forecast,'H')
    if debug==True:
        print "*********** final*************"
        print ("Type de forecast: %s" %type(forecast))
        print forecast
    save2csv(forecast,"Traffic_in")

if __name__ == '__main__':
 
#     doTest2_ConstantValuePredict()
#     doTest3_NonConstantValuePredict()
#     doTest4_2hours()
#     doTest5_ValuesWithPeakDetect()
    doTest6_ValuesWithPeakDetect()